# Projects

---

### Real-Time News Sentiment Analysis Pipeline on GCP
With all the negativity in news headlines recently, it can be a real strain on mental health when you are constantly bombarded with negative news articles and headlines. This project was intended to assist, when you just need a break from negative news articles and want to filter news by positive, neutral or negative sentiment. This was the problem I wanted to create a solution for and by developing a pipeline that performs real-time sentiment analysis on news articles and allows for the user to filter results based on positive or negative sentiment of each article.

[Real-Time News Sentiment Analysis](/images/News-Sentiment-Analysis.pdf)
<img src="images/bandicam 2021-01-26 17-25-43-560.jpg"/>

---

### Udacity Data Engineering Nanodegree Projects with AWS, Spark & Airflow
This is a collection of projects that were part of the Udacity Data Engineering Nanodegree program. These projects are completed in relation to a mock start-up called ‘Sparkify’. Sparkify is a music streaming application that wants to start analyzing their songs, song plays and user data. So using modern data engineering tools I built 4 projects to assist Sparkify in accomplishing it’s goals.


[Data Engineering Nanodegree Projects](images/UdacityDEND-powerpoint.pdf)
<img src="images/bandicam 2021-02-12 19-00-09-410.jpg"/>

---

### Sales profit forecasting with Prophet model
The objective of this project is to determine the ‘health’ of all 3 product categories in this dataset. We want to understand and capture trends & seasonality, but also predict profits for each category for the next couple years. While doing so, I will explore some of the best models and statistical methods to work with and make predictions with time-series data.

[Sales Profit Predictions with Prophet](images/Superstore_ML.pdf)
<img src="images/bandicam 2021-02-06 15-59-19-940.jpg"/>

---

### Web Scraping F1 race results and exploring Snowflake
I completed all the web scraping and data cleaning utilizing python and BeautifulSoup within the Jupyter environment and saved the final dataframe as a csv file in a S3 bucket. Next, I connected to the S3 bucket with a Snowflake data warehouse created a database and tables. I utilized SQL to create some visualizations within the Snowflake environment. Finally, I connected my data warehouse to Tableau and created a simple dashboard of my analysis and exploration to be able to visualize my findings in more depth.

[Web Scraping F1 Race results and exploring Snowflake](images/f1_prezi.pdf)
<img src="images/bandicam 2021-02-06 13-41-58-874.jpg"/>

---

### San Francisco Bike Share Rental Demographics Dashboard with Tableau
Who are the customers? Which Stations are the busiest? What days have the most rentals?
These are the question I was trying to address when exploring the bike share dataset.

[Bike Share Dashboard Exploring Rental Demographics with Tableau](images/BikeshareDash.pdf)
<img src="images/bandicam 2021-02-06 16-05-27-005.jpg"/>

---
